{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install corus","metadata":{"execution":{"iopub.status.busy":"2022-05-24T15:41:14.500254Z","iopub.execute_input":"2022-05-24T15:41:14.501102Z","iopub.status.idle":"2022-05-24T15:41:27.38507Z","shell.execute_reply.started":"2022-05-24T15:41:14.500951Z","shell.execute_reply":"2022-05-24T15:41:27.384173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://github.com/ods-ai-ml4sg/proj_news_viz/releases/download/data/tass-001.csv.gz","metadata":{"execution":{"iopub.status.busy":"2022-05-24T15:41:27.387145Z","iopub.execute_input":"2022-05-24T15:41:27.387415Z","iopub.status.idle":"2022-05-24T15:44:47.660139Z","shell.execute_reply.started":"2022-05-24T15:41:27.387375Z","shell.execute_reply":"2022-05-24T15:44:47.659362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pymorphy2[fast]","metadata":{"execution":{"iopub.status.busy":"2022-05-24T15:44:47.661864Z","iopub.execute_input":"2022-05-24T15:44:47.662362Z","iopub.status.idle":"2022-05-24T15:45:22.895043Z","shell.execute_reply.started":"2022-05-24T15:44:47.662322Z","shell.execute_reply":"2022-05-24T15:45:22.894218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install razdel","metadata":{"execution":{"iopub.status.busy":"2022-05-24T15:45:22.897476Z","iopub.execute_input":"2022-05-24T15:45:22.898007Z","iopub.status.idle":"2022-05-24T15:45:33.568535Z","shell.execute_reply.started":"2022-05-24T15:45:22.897968Z","shell.execute_reply":"2022-05-24T15:45:33.567663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport random\ntqdm.pandas()\nimport pandas as pd\nfrom razdel import tokenize\nfrom corus import load_ods_tass\nfrom string import punctuation\nimport pymorphy2\nm = pymorphy2.MorphAnalyzer()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T15:45:33.571779Z","iopub.execute_input":"2022-05-24T15:45:33.572008Z","iopub.status.idle":"2022-05-24T15:45:33.948904Z","shell.execute_reply.started":"2022-05-24T15:45:33.571981Z","shell.execute_reply":"2022-05-24T15:45:33.948171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = './tass-001.csv.gz'\nrecords = load_ods_tass(path)\n\ntitles = []  # ~5 минут\nfor i in records:\n    \n    titles.append(i.title)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T15:45:33.950015Z","iopub.execute_input":"2022-05-24T15:45:33.95027Z","iopub.status.idle":"2022-05-24T15:47:35.630914Z","shell.execute_reply.started":"2022-05-24T15:45:33.950237Z","shell.execute_reply":"2022-05-24T15:47:35.630102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def my_tokenize(x):\n    return [_.text for _ in list(tokenize(x))]","metadata":{"execution":{"iopub.status.busy":"2022-05-24T15:47:35.632512Z","iopub.execute_input":"2022-05-24T15:47:35.632785Z","iopub.status.idle":"2022-05-24T15:47:35.639257Z","shell.execute_reply.started":"2022-05-24T15:47:35.632739Z","shell.execute_reply":"2022-05-24T15:47:35.638537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame()\ndf['text'] = titles[:100000]\ndf = df.dropna()\ndf['tokens'] = df['text'].progress_apply(my_tokenize)\ndf['corrupted_tokens'] = df['tokens']","metadata":{"execution":{"iopub.status.busy":"2022-05-24T15:47:35.640649Z","iopub.execute_input":"2022-05-24T15:47:35.640911Z","iopub.status.idle":"2022-05-24T15:47:45.301599Z","shell.execute_reply.started":"2022-05-24T15:47:35.640879Z","shell.execute_reply":"2022-05-24T15:47:45.300731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-05-24T15:47:45.303195Z","iopub.execute_input":"2022-05-24T15:47:45.303562Z","iopub.status.idle":"2022-05-24T15:47:45.328541Z","shell.execute_reply.started":"2022-05-24T15:47:45.303517Z","shell.execute_reply":"2022-05-24T15:47:45.327748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def corrupt_tokens(tokens):\n    cases = ['nomn', 'gent', 'datv', 'accs', 'ablt', 'loct']\n    try:\n        corrupted = []\n        for i, t in enumerate(tokens):\n            ## IF COUNT PREP == 0 -> NONE\n            if m.parse(t)[0].tag.POS == 'NOUN':\n                if m.parse(tokens[i-1])[0].tag.POS == 'PREP':\n                    old_case = m.parse(t)[0].tag.case\n                    new_case = old_case\n                    while new_case == old_case:\n                        new_case = random.choice(cases)\n                    token = m.parse(t)[0].inflect({new_case}).word\n                else:\n                    token =  m.parse(t)[0].word\n            else:\n                token =  m.parse(t)[0].word\n            corrupted.append(token)\n        return corrupted\n    except AttributeError:\n        print(tokens)\n        return None","metadata":{"execution":{"iopub.status.busy":"2022-05-24T15:47:45.331624Z","iopub.execute_input":"2022-05-24T15:47:45.331923Z","iopub.status.idle":"2022-05-24T15:47:45.340286Z","shell.execute_reply.started":"2022-05-24T15:47:45.331895Z","shell.execute_reply":"2022-05-24T15:47:45.339428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-05-24T15:47:45.341849Z","iopub.execute_input":"2022-05-24T15:47:45.342244Z","iopub.status.idle":"2022-05-24T15:47:45.363159Z","shell.execute_reply.started":"2022-05-24T15:47:45.342209Z","shell.execute_reply":"2022-05-24T15:47:45.362393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['corrupted_tokens'] = df['corrupted_tokens'].progress_apply(corrupt_tokens)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T15:47:45.364532Z","iopub.execute_input":"2022-05-24T15:47:45.364786Z","iopub.status.idle":"2022-05-24T15:49:24.437383Z","shell.execute_reply.started":"2022-05-24T15:47:45.36475Z","shell.execute_reply":"2022-05-24T15:49:24.436702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('data_corrupted.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-24T15:49:24.43864Z","iopub.execute_input":"2022-05-24T15:49:24.439064Z","iopub.status.idle":"2022-05-24T15:49:26.235264Z","shell.execute_reply.started":"2022-05-24T15:49:24.439025Z","shell.execute_reply":"2022-05-24T15:49:26.234532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokens_to_text(x):\n    return ' '.join(x)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T15:49:26.236556Z","iopub.execute_input":"2022-05-24T15:49:26.236809Z","iopub.status.idle":"2022-05-24T15:49:26.243115Z","shell.execute_reply.started":"2022-05-24T15:49:26.236776Z","shell.execute_reply":"2022-05-24T15:49:26.242361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def text_preproc(x):\n    for p in punctuation + '«»':\n        x = x.replace(p, '')\n    x = x.replace('ё', 'е')\n    while '  ' in x:\n        x = x.replace('  ', ' ')\n    return x.lower()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:52:19.56286Z","iopub.execute_input":"2022-05-24T21:52:19.563136Z","iopub.status.idle":"2022-05-24T21:52:19.57037Z","shell.execute_reply.started":"2022-05-24T21:52:19.563106Z","shell.execute_reply":"2022-05-24T21:52:19.567841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.dropna()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T15:49:26.253491Z","iopub.execute_input":"2022-05-24T15:49:26.253824Z","iopub.status.idle":"2022-05-24T15:49:26.31804Z","shell.execute_reply.started":"2022-05-24T15:49:26.253787Z","shell.execute_reply":"2022-05-24T15:49:26.317356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['corrupted_text'] = df['corrupted_tokens'].apply(tokens_to_text)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T15:49:26.319452Z","iopub.execute_input":"2022-05-24T15:49:26.319941Z","iopub.status.idle":"2022-05-24T15:49:26.415447Z","shell.execute_reply.started":"2022-05-24T15:49:26.319905Z","shell.execute_reply":"2022-05-24T15:49:26.414714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['text'] = df['text'].apply(text_preproc)\ndf['corrupted_text'] = df['corrupted_text'].apply(text_preproc)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T15:49:26.41685Z","iopub.execute_input":"2022-05-24T15:49:26.417109Z","iopub.status.idle":"2022-05-24T15:49:27.812218Z","shell.execute_reply.started":"2022-05-24T15:49:26.417076Z","shell.execute_reply":"2022-05-24T15:49:27.811462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check_prep(x):\n    prep = 0\n    for token in x:\n        if m.parse(token)[0].tag.POS == 'PREP':\n            prep += 1\n    if prep == 0:\n        return None\n    else:\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-05-24T15:49:27.813507Z","iopub.execute_input":"2022-05-24T15:49:27.813754Z","iopub.status.idle":"2022-05-24T15:49:27.821583Z","shell.execute_reply.started":"2022-05-24T15:49:27.813722Z","shell.execute_reply":"2022-05-24T15:49:27.820877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['check_prep'] = df['corrupted_tokens'].progress_apply(check_prep)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T15:49:27.82301Z","iopub.execute_input":"2022-05-24T15:49:27.823555Z","iopub.status.idle":"2022-05-24T15:50:04.766585Z","shell.execute_reply.started":"2022-05-24T15:49:27.823516Z","shell.execute_reply":"2022-05-24T15:50:04.76576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.dropna()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T15:50:04.767896Z","iopub.execute_input":"2022-05-24T15:50:04.768274Z","iopub.status.idle":"2022-05-24T15:50:04.871736Z","shell.execute_reply.started":"2022-05-24T15:50:04.768231Z","shell.execute_reply":"2022-05-24T15:50:04.870988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['corrupted_text', 'text']].to_csv('df_10k.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-24T15:50:04.87296Z","iopub.execute_input":"2022-05-24T15:50:04.873202Z","iopub.status.idle":"2022-05-24T15:50:05.623047Z","shell.execute_reply.started":"2022-05-24T15:50:04.87317Z","shell.execute_reply":"2022-05-24T15:50:05.622308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['corrupted_text', 'text']]","metadata":{"execution":{"iopub.status.busy":"2022-05-24T15:50:05.624483Z","iopub.execute_input":"2022-05-24T15:50:05.624732Z","iopub.status.idle":"2022-05-24T15:50:05.640771Z","shell.execute_reply.started":"2022-05-24T15:50:05.624699Z","shell.execute_reply":"2022-05-24T15:50:05.640108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# T5","metadata":{}},{"cell_type":"code","source":"!pip install transformers sentencepiece","metadata":{"execution":{"iopub.status.busy":"2022-05-24T15:50:05.641974Z","iopub.execute_input":"2022-05-24T15:50:05.642597Z","iopub.status.idle":"2022-05-24T15:50:14.368079Z","shell.execute_reply.started":"2022-05-24T15:50:05.642558Z","shell.execute_reply":"2022-05-24T15:50:14.367224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch \nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\nraw_model = 'cointegrated/rut5-base-multitask' \nmodel = T5ForConditionalGeneration.from_pretrained(raw_model).cuda();\ntokenizer = T5Tokenizer.from_pretrained(raw_model)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-5)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:35:21.688799Z","iopub.execute_input":"2022-05-24T22:35:21.689074Z","iopub.status.idle":"2022-05-24T22:37:00.78066Z","shell.execute_reply.started":"2022-05-24T22:35:21.689045Z","shell.execute_reply":"2022-05-24T22:37:00.77978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:37:00.782744Z","iopub.execute_input":"2022-05-24T22:37:00.783017Z","iopub.status.idle":"2022-05-24T22:37:00.791602Z","shell.execute_reply.started":"2022-05-24T22:37:00.782981Z","shell.execute_reply":"2022-05-24T22:37:00.790474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, test = train_test_split(df[['corrupted_text', 'text']])","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:37:00.792947Z","iopub.execute_input":"2022-05-24T22:37:00.793311Z","iopub.status.idle":"2022-05-24T22:37:01.619018Z","shell.execute_reply.started":"2022-05-24T22:37:00.793271Z","shell.execute_reply":"2022-05-24T22:37:01.61825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pairs = train.values.tolist()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:37:01.621026Z","iopub.execute_input":"2022-05-24T22:37:01.621315Z","iopub.status.idle":"2022-05-24T22:37:01.662542Z","shell.execute_reply.started":"2022-05-24T22:37:01.621278Z","shell.execute_reply":"2022-05-24T22:37:01.661777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import trange\nimport random\nimport numpy as np\n\nbatch_size = 16  # сколько примеров показываем модели за один шаг\nreport_steps = 200  # раз в сколько шагов печатаем результат\nepochs = 3  # сколько раз мы покажем данные модели ОСТАВИТЬ 2 ЭПОХИ\n\nmodel.train()\nlosses = []\nfor epoch in range(epochs):\n    print('EPOCH', epoch)\n    random.shuffle(pairs)\n    for i in trange(0, int(len(pairs) / batch_size)):\n        batch = pairs[i * batch_size: (i + 1) * batch_size]\n        # кодируем вопрос и ответ \n        x = tokenizer([p[0] for p in batch], return_tensors='pt', padding=\"max_length\", max_length=100,).to(model.device)\n        y = tokenizer([p[1] for p in batch], return_tensors='pt', padding=\"max_length\", max_length=100,).to(model.device)\n        # -100 - специальное значение, позволяющее не учитывать токены\n        y.input_ids[y.input_ids == 0] = -100\n        # вычисляем функцию потерь\n        loss = model(\n            input_ids=x.input_ids,\n            attention_mask=x.attention_mask,\n            labels=y.input_ids,\n            decoder_attention_mask=y.attention_mask,\n            return_dict=True\n        ).loss\n        # делаем шаг градиентного спуска\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        # печатаем скользящее среднее значение функции потерь\n        losses.append(loss.item())\n        if i % report_steps == 0:\n            print('step', i, 'loss', np.mean(losses[-report_steps:]))","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:37:01.663698Z","iopub.execute_input":"2022-05-24T22:37:01.664219Z","iopub.status.idle":"2022-05-25T00:22:30.138034Z","shell.execute_reply.started":"2022-05-24T22:37:01.664179Z","shell.execute_reply":"2022-05-25T00:22:30.137376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\n\ndef answer(x, **kwargs):\n    inputs = tokenizer(x, return_tensors='pt',padding=\"max_length\", max_length=100,).to(model.device)\n    with torch.no_grad():\n        hypotheses = model.generate(**inputs, **kwargs, max_length=100)\n    return tokenizer.decode(hypotheses[0], skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T00:25:27.295641Z","iopub.execute_input":"2022-05-25T00:25:27.296335Z","iopub.status.idle":"2022-05-25T00:25:27.304953Z","shell.execute_reply.started":"2022-05-25T00:25:27.296296Z","shell.execute_reply":"2022-05-25T00:25:27.304215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = test[:5000]","metadata":{"execution":{"iopub.status.busy":"2022-05-25T00:25:38.515013Z","iopub.execute_input":"2022-05-25T00:25:38.515294Z","iopub.status.idle":"2022-05-25T00:25:38.520918Z","shell.execute_reply.started":"2022-05-25T00:25:38.515266Z","shell.execute_reply":"2022-05-25T00:25:38.51942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['preds'] = test_df['corrupted_text'].progress_apply(answer)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T00:25:43.090819Z","iopub.execute_input":"2022-05-25T00:25:43.091082Z","iopub.status.idle":"2022-05-25T01:15:41.564544Z","shell.execute_reply.started":"2022-05-25T00:25:43.091054Z","shell.execute_reply":"2022-05-25T01:15:41.563224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c = 0\nhits = []\nfor i in test_df[['text', 'preds']].values.tolist():\n    if i[0] == i[1]:\n        c += 1\n        hits.append(True)\n    else:\n        hits.append(False)\n\nc/len(test_df[['text', 'preds']].values.tolist())","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:16:27.097008Z","iopub.execute_input":"2022-05-25T01:16:27.097265Z","iopub.status.idle":"2022-05-25T01:16:27.112875Z","shell.execute_reply.started":"2022-05-25T01:16:27.097237Z","shell.execute_reply":"2022-05-25T01:16:27.111981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['hit'] = hits","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:16:31.591985Z","iopub.execute_input":"2022-05-25T01:16:31.592236Z","iopub.status.idle":"2022-05-25T01:16:31.60093Z","shell.execute_reply.started":"2022-05-25T01:16:31.592208Z","shell.execute_reply":"2022-05-25T01:16:31.6001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.to_csv('preds_cointegrated_ruT5-base.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:16:58.825162Z","iopub.execute_input":"2022-05-25T01:16:58.825697Z","iopub.status.idle":"2022-05-25T01:16:58.894852Z","shell.execute_reply.started":"2022-05-25T01:16:58.825657Z","shell.execute_reply":"2022-05-25T01:16:58.894095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in test_df[test_df['hit'] == False][['text', 'preds']].values.tolist():\n    print(f'TRUE: \\t {i[0]}\\nPRED: \\t {i[1]}')\n    print()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:17:30.996135Z","iopub.execute_input":"2022-05-25T01:17:30.99658Z","iopub.status.idle":"2022-05-25T01:17:31.129709Z","shell.execute_reply.started":"2022-05-25T01:17:30.996539Z","shell.execute_reply":"2022-05-25T01:17:31.129113Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RULEC-GEC test dataset","metadata":{}},{"cell_type":"code","source":"def parse(lines):\n    source_sentences = []\n    gold_edits = []\n    for item in paragraphs(lines):\n        sentence = [line[2:].strip() for line in item if line.startswith('S ')]\n        assert sentence != []\n        annotations = {}\n        for line in item[1:]:\n            if line.startswith('I ') or line.startswith('S '):\n                continue\n            assert line.startswith('A ')\n            line = line[2:]\n            fields = line.split('|||')\n            start_offset = int(fields[0].split()[0])\n            end_offset = int(fields[0].split()[1])\n            etype = fields[1]\n            \n            \n            if etype == 'noop':\n                start_offset = -1\n                end_offset = -1\n            \n            corrections = [c.strip() if c != '-NONE-' else ''\n                           for c in fields[2].split('||')]\n    \n            # NOTE: start and end are *token* offsets\n            original = ' '.join(\n                    ' '.join(sentence).split()[start_offset:end_offset])\n            annotator = int(fields[5])\n            if annotator not in annotations.keys():\n                annotations[annotator] = []\n            annotations[annotator].append((start_offset, end_offset,\n                                           original, corrections, etype))\n        tok_offset = 0\n        for this_sentence in sentence:\n            tok_offset += len(this_sentence.split())\n            source_sentences.append(this_sentence)\n            this_edits = {}\n            for annotator, annotation in annotations.items():\n                this_edits[annotator] = [edit for edit in annotation if edit[0] <= tok_offset and edit[1] <= tok_offset and edit[0] >= 0 and edit[1] >= 0]\n            if len(this_edits) == 0:\n                this_edits[0] = []\n            gold_edits.append(this_edits)\n    return (source_sentences, gold_edits)\n\n\ndef paragraphs(lines):\n    paragraph = []\n    for line in lines:\n        if line == '':\n            if paragraph:\n                yield paragraph\n                paragraph = []\n        else:\n            paragraph.append(line)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:18:09.092511Z","iopub.execute_input":"2022-05-25T01:18:09.093038Z","iopub.status.idle":"2022-05-25T01:18:09.117092Z","shell.execute_reply.started":"2022-05-25T01:18:09.092982Z","shell.execute_reply":"2022-05-25T01:18:09.116294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def apply_corrections(sentence, corrections):\n    \"\"\"Return a new sentence with corrections applied.\n    Sentence should be a whitespace-separated tokenised string. Corrections\n    should be a list of corrections.\n    \"\"\"\n    tokens = sentence.split(' ')\n    offset = 0\n\n    for c in corrections:\n        tokens, offset = _apply_correction(tokens, c, offset)\n\n    return ' '.join(tokens)\n\ndef apply_bad_corrections(sentence, corrections):\n    \"\"\"Return a new sentence with corrections applied.\n    Sentence should be a whitespace-separated tokenised string. Corrections\n    should be a list of corrections.\n    \"\"\"\n    tokens = sentence.split(' ')\n    offset = 0\n\n    for c in corrections:\n        tokens, offset = _apply_bad_correction(tokens, c, offset)\n\n    return ' '.join(tokens)\n\n\ndef _apply_correction(tokens, correction, offset):\n    \"\"\"Apply a single correction to a list of tokens.\"\"\"\n    start_token_offset, end_token_offset, bad_token, insertion, etype = correction\n    to_insert = insertion[0].split(' ')\n    end_token_offset += (len(to_insert) - 1)\n    \n    \n    to_insert_filtered = [t for t in to_insert if t != '']\n\n    head = tokens[:start_token_offset + offset]\n    tail = tokens[end_token_offset + offset:]\n\n    new_tokens = head + to_insert_filtered + tail\n\n    new_offset = len(to_insert_filtered) - (end_token_offset - start_token_offset) + offset\n\n    return new_tokens, new_offset\n\n\ndef _apply_bad_correction(tokens, correction, offset):\n    \"\"\"Apply a single correction to a list of tokens.\"\"\"\n    start_token_offset, end_token_offset, bad_token, insertion, etype = correction\n    to_insert = insertion[0].split(' ')\n    end_token_offset += (len(to_insert) - 1)\n    \n    \n    if etype == 'Сущ.:Падеж':\n        to_insert_filtered = [bad_token]\n    else:\n        to_insert_filtered = [t for t in to_insert if t != '']\n\n    head = tokens[:start_token_offset + offset]\n    tail = tokens[end_token_offset + offset:]\n\n    new_tokens = head + to_insert_filtered + tail\n\n    new_offset = len(to_insert_filtered) - (end_token_offset - start_token_offset) + offset\n\n    return new_tokens, new_offset","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:18:10.943718Z","iopub.execute_input":"2022-05-25T01:18:10.943987Z","iopub.status.idle":"2022-05-25T01:18:10.958299Z","shell.execute_reply.started":"2022-05-25T01:18:10.943953Z","shell.execute_reply":"2022-05-25T01:18:10.957632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_corrections(path):\n    output = []\n    with open(path, 'r', encoding='utf-8') as f:\n        lines = f.read().split('\\n')\n\n        sentences, corrections = parse(lines)\n        for s, c in zip(sentences, corrections):\n            output.append([apply_corrections(s, c[0])])\n    return output\n\ndef get_corruptions(path):\n    output = []\n    with open(path, 'r', encoding='utf-8') as f:\n        lines = f.read().split('\\n')\n\n        sentences, corrections = parse(lines)\n        for s, c in zip(sentences, corrections):\n            output.append([apply_bad_corrections(s, c[0])])\n    return output\n","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:18:12.400432Z","iopub.execute_input":"2022-05-25T01:18:12.400988Z","iopub.status.idle":"2022-05-25T01:18:12.408042Z","shell.execute_reply.started":"2022-05-25T01:18:12.400951Z","shell.execute_reply":"2022-05-25T01:18:12.407288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target1 = get_corrections('../input/diplom/RULEC-GEC.train.M2')\nsource1 = get_corruptions('../input/diplom/RULEC-GEC.train.M2')\n\ntarget2 = get_corrections('../input/diplom/RULEC-GEC.dev.M2')\nsource2 = get_corruptions('../input/diplom/RULEC-GEC.dev.M2')","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:18:14.816481Z","iopub.execute_input":"2022-05-25T01:18:14.817028Z","iopub.status.idle":"2022-05-25T01:18:15.074174Z","shell.execute_reply.started":"2022-05-25T01:18:14.816994Z","shell.execute_reply":"2022-05-25T01:18:15.073362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_rulec1 = pd.DataFrame()\ntest_rulec2 = pd.DataFrame()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:18:16.17612Z","iopub.execute_input":"2022-05-25T01:18:16.176376Z","iopub.status.idle":"2022-05-25T01:18:16.183483Z","shell.execute_reply.started":"2022-05-25T01:18:16.176347Z","shell.execute_reply":"2022-05-25T01:18:16.182684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_rulec1['target'] = [x[0] for x in target1]\ntest_rulec1['source'] = [x[0] for x in source1]\n\ntest_rulec2['target'] = [x[0] for x in target2]\ntest_rulec2['source'] = [x[0] for x in source2]","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:18:17.458138Z","iopub.execute_input":"2022-05-25T01:18:17.458388Z","iopub.status.idle":"2022-05-25T01:18:17.471624Z","shell.execute_reply.started":"2022-05-25T01:18:17.45836Z","shell.execute_reply":"2022-05-25T01:18:17.470768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_rulec = pd.concat([test_rulec1, test_rulec2])","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:18:19.154294Z","iopub.execute_input":"2022-05-25T01:18:19.15497Z","iopub.status.idle":"2022-05-25T01:18:19.16148Z","shell.execute_reply.started":"2022-05-25T01:18:19.154929Z","shell.execute_reply":"2022-05-25T01:18:19.160711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_rulec","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:18:19.922154Z","iopub.execute_input":"2022-05-25T01:18:19.922682Z","iopub.status.idle":"2022-05-25T01:18:19.934904Z","shell.execute_reply.started":"2022-05-25T01:18:19.922642Z","shell.execute_reply":"2022-05-25T01:18:19.934191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"case = []\nfor row in test_rulec.values.tolist():\n    if row[0] == row[1]:\n        case.append(np.nan)\n    else:\n        case.append(True)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:18:23.915121Z","iopub.execute_input":"2022-05-25T01:18:23.915368Z","iopub.status.idle":"2022-05-25T01:18:23.927095Z","shell.execute_reply.started":"2022-05-25T01:18:23.91534Z","shell.execute_reply":"2022-05-25T01:18:23.926225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_rulec['case'] = case","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:18:24.89071Z","iopub.execute_input":"2022-05-25T01:18:24.890981Z","iopub.status.idle":"2022-05-25T01:18:24.897657Z","shell.execute_reply.started":"2022-05-25T01:18:24.890951Z","shell.execute_reply":"2022-05-25T01:18:24.896772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_rulec = test_rulec.dropna()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:18:25.778527Z","iopub.execute_input":"2022-05-25T01:18:25.778776Z","iopub.status.idle":"2022-05-25T01:18:25.789218Z","shell.execute_reply.started":"2022-05-25T01:18:25.778749Z","shell.execute_reply":"2022-05-25T01:18:25.788486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_rulec","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:18:26.660349Z","iopub.execute_input":"2022-05-25T01:18:26.661048Z","iopub.status.idle":"2022-05-25T01:18:26.672093Z","shell.execute_reply.started":"2022-05-25T01:18:26.661016Z","shell.execute_reply":"2022-05-25T01:18:26.671423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_rulec['target'] = test_rulec['target'].apply(text_preproc)\ntest_rulec['source'] = test_rulec['source'].apply(text_preproc)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:18:31.81273Z","iopub.execute_input":"2022-05-25T01:18:31.812988Z","iopub.status.idle":"2022-05-25T01:18:31.834806Z","shell.execute_reply.started":"2022-05-25T01:18:31.812961Z","shell.execute_reply":"2022-05-25T01:18:31.833947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_rulec","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:18:33.944798Z","iopub.execute_input":"2022-05-25T01:18:33.945564Z","iopub.status.idle":"2022-05-25T01:18:33.957347Z","shell.execute_reply.started":"2022-05-25T01:18:33.94553Z","shell.execute_reply":"2022-05-25T01:18:33.9566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_rulec['preds'] = test_rulec['source'].progress_apply(answer)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:18:39.38664Z","iopub.execute_input":"2022-05-25T01:18:39.386889Z","iopub.status.idle":"2022-05-25T01:27:31.117905Z","shell.execute_reply.started":"2022-05-25T01:18:39.386862Z","shell.execute_reply":"2022-05-25T01:27:31.11728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c = 0\nhits = []\nfor i in test_rulec[['target', 'preds']].values.tolist():\n    if i[0][:-1] == i[1]:\n        c += 1\n        hits.append(True)\n    else:\n        hits.append(False)\n\nc/len(test_rulec[['target', 'preds']].values.tolist())","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:27:37.418176Z","iopub.execute_input":"2022-05-25T01:27:37.418448Z","iopub.status.idle":"2022-05-25T01:27:37.429373Z","shell.execute_reply.started":"2022-05-25T01:27:37.418399Z","shell.execute_reply":"2022-05-25T01:27:37.428449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_rulec['hit'] = hits","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:28:01.630791Z","iopub.execute_input":"2022-05-25T01:28:01.631046Z","iopub.status.idle":"2022-05-25T01:28:01.636426Z","shell.execute_reply.started":"2022-05-25T01:28:01.631017Z","shell.execute_reply":"2022-05-25T01:28:01.635469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in test_rulec[test_rulec['hit'] == False][['target', 'preds', 'source']].values.tolist():\n    print(f'TRUE: \\t {i[0]}\\nPRED: \\t {i[1]}\\nINPT: \\t {i[2]}')\n    print()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:28:04.474298Z","iopub.execute_input":"2022-05-25T01:28:04.474902Z","iopub.status.idle":"2022-05-25T01:28:04.587433Z","shell.execute_reply.started":"2022-05-25T01:28:04.474863Z","shell.execute_reply":"2022-05-25T01:28:04.586869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answer('текст включает в себя этимология и история употребления слова')","metadata":{"execution":{"iopub.status.busy":"2022-05-24T19:05:20.038149Z","iopub.execute_input":"2022-05-24T19:05:20.038451Z","iopub.status.idle":"2022-05-24T19:05:20.334484Z","shell.execute_reply.started":"2022-05-24T19:05:20.038404Z","shell.execute_reply":"2022-05-24T19:05:20.333469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MLM: BERT & RoBERTa","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}